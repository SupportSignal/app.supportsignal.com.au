# Story 6.3: Developer Prompt Testing & Interpolation Interface

## Status
Ready

## Story
**As a** developer,  
**I want** a comprehensive prompt testing and visualization interface within the existing developer controls,  
**so that** I can test, debug, and optimize AI prompts in real-time without modifying the database or system configuration, enabling effective verification of Story 6.2 phase-specific prompts and ongoing prompt development.

## Acceptance Criteria

1. **Developer Controls Extension**: Extend existing developer toolbar with comprehensive prompt testing capabilities accessible only to users with developer permissions

2. **Prompt Template Display**: Show current active prompt template being used for any AI operation, with real-time selection based on context

3. **Contextual Variable Loading**: Display all available variables from the current incident workflow with visual indicators (green lines) for variables that match template placeholders

4. **Extensible Variable System**: Allow adding/modifying variables for testing without database persistence, including custom key-value pairs not normally available

5. **Real-time Interpolation Preview**: Show live preview of fully interpolated prompt with current variable values, updating automatically as variables change

6. **Template Override System**: Allow temporary prompt template modifications for A/B testing without affecting the production prompt system

7. **Test Execution**: Execute prompts with current variables against actual AI services and display responses with metadata (tokens, cost, timing)

8. **Export for External Testing**: Copy template, variable assignments (with green indicators), and interpolated prompt as machine-readable structure for external LLM testing

9. **No Database Persistence**: All modifications are temporary session-based and never stored in the database

10. **Context Awareness**: Automatically show relevant prompt testing interface based on current workflow step or page context

## Estimation & Planning

### Story Points
8

### Estimated Complexity  
High

### Estimated Time
3-4 days

### Risk Level
Medium-High (Complex testing override architecture)

## Tasks / Subtasks

- [ ] **Task 6.3.1: Design Testing Override Architecture** (AC: 6, 9)
  - [ ] Subtask 6.3.1.1: Design session-based prompt override system that intercepts normal prompt resolution
  - [ ] Subtask 6.3.1.2: Create testing context propagation through AI service calls without breaking normal flow
  - [ ] Subtask 6.3.1.3: Implement clean abstraction layer for testing overrides applicable to all prompt types
  - [ ] Subtask 6.3.1.4: Design fallback mechanisms when testing session expires or fails

- [ ] **Task 6.3.2: Extend Developer Controls UI** (AC: 1, 2, 10)
  - [ ] Subtask 6.3.2.1: Extend existing developer toolbar component with new prompt testing panel
  - [ ] Subtask 6.3.2.2: Create responsive layout with left panel (prompt/template), right panel (variables), bottom panel (preview/results)
  - [ ] Subtask 6.3.2.3: Implement context-aware prompt detection and display based on current page/workflow
  - [ ] Subtask 6.3.2.4: Add developer-only access control integration with existing permission system

- [ ] **Task 6.3.3: Contextual Variable Loading System** (AC: 3, 4)
  - [ ] Subtask 6.3.3.1: Create service to extract all available variables from current incident workflow context
  - [ ] Subtask 6.3.3.2: Implement property grid component with green indicator system for matching placeholders
  - [ ] Subtask 6.3.3.3: Build extensible variable editor allowing custom key-value pairs for testing
  - [ ] Subtask 6.3.3.4: Add variable validation and type checking with error display

- [ ] **Task 6.3.4: Real-time Prompt Resolution Engine** (AC: 5, 6)
  - [ ] Subtask 6.3.4.1: Create live prompt interpolation service with template variable substitution
  - [ ] Subtask 6.3.4.2: Implement template override system allowing temporary prompt modifications
  - [ ] Subtask 6.3.4.3: Build preview component with syntax highlighting and real-time updates
  - [ ] Subtask 6.3.4.4: Add validation for template syntax and variable matching

- [ ] **Task 6.3.5: AI Testing Execution System** (AC: 7)
  - [ ] Subtask 6.3.5.1: Create testing-specific AI service wrapper that uses override context
  - [ ] Subtask 6.3.5.2: Implement test execution panel with progress indicators and response display
  - [ ] Subtask 6.3.5.3: Add metadata display for tokens used, cost, timing, and model information
  - [ ] Subtask 6.3.5.4: Create response analysis and comparison features

- [ ] **Task 6.3.6: Export and Copy Functionality** (AC: 8)
  - [ ] Subtask 6.3.6.1: Design machine-readable export format for external testing
  - [ ] Subtask 6.3.6.2: Implement copy functionality for template, variables, and interpolated result
  - [ ] Subtask 6.3.6.3: Add visual indicators in exported data for matched vs custom variables
  - [ ] Subtask 6.3.6.4: Create formatted output suitable for ChatGPT/external LLM testing

- [ ] **Task 6.3.7: Integration Testing and Validation** (AC: 1-10)
  - [ ] Subtask 6.3.7.1: Test integration with existing developer toolbar and permission system
  - [ ] Subtask 6.3.7.2: Validate Story 6.2 phase-specific prompts work correctly through testing interface
  - [ ] Subtask 6.3.7.3: Test all prompt types (clarification, enhancement, mock answers) work with override system
  - [ ] Subtask 6.3.7.4: Verify no database persistence and proper session cleanup

## Documentation Impact Assessment

This story establishes critical developer experience patterns for AI prompt testing and development:

**Architectural Patterns to Establish:**
- Session-based testing override systems for AI services
- Real-time prompt interpolation and preview patterns
- Developer tool integration with production AI workflows
- Contextual variable extraction from workflow state
- Temporary modification systems with production isolation

**Documentation Updates Needed:**
- Developer experience tooling architecture
- Prompt testing and debugging workflows
- AI service override pattern documentation
- Variable extraction and context management patterns

**Knowledge Capture:**
- Testing override architecture patterns for AI services
- Developer tool integration strategies for complex workflows
- Real-time preview and interpolation implementation approaches
- Session-based modification patterns without persistence

## Dev Notes

### Previous Story Insights
From Story 6.2 (Phase-Specific Question Generation Prompts):
- **Four Phase-Specific Prompts**: Templates for `before_event`, `during_event`, `end_event`, `post_event` exist in DEFAULT_PROMPTS
- **Dynamic Prompt Selection**: questionGenerator.ts uses `generate_clarification_questions_${args.phase}` pattern
- **Template System**: Prompts use `{{participantName}}`, `{{reporterName}}`, `{{location}}`, `{{eventDateTime}}`, `{{narrativeText}}`
- **Database Architecture**: ai_prompts table with prompt_name, prompt_template, subsystem fields

From Story 6.1 (Core AI Prompt Management Foundation):
- **Prompt Resolution**: promptManager.getActivePrompt() used throughout AI services
- **Variable Interpolation**: Template resolution with caching system (5-minute TTL)
- **Admin Interface**: Existing `/admin/ai-prompts` page with PromptTemplateList component
- **Authentication Pattern**: sessionToken + requirePermission() for system access

### Current Developer Experience Analysis [Source: Screenshot provided by user]

**Existing Developer Controls**:
- Located at bottom of incident workflows (visible in user screenshot)
- Shows "Developer Tools" with "Step 6 of 8" context
- Currently has "Fill Form", "Fill Narrative", "Fill Q&A" sample data buttons
- Shows workflow context: "Copy (6/8)", "Import", workflow ID "3h7q3wnt..."

**Integration Point**: Story 6.3 extends this existing developer toolbar rather than creating new interface.

### Data Models [Source: apps/convex/schema.ts, Story 6.1]

**AI Prompts Schema** (existing, used by testing override system):
```typescript
ai_prompts: defineTable({
  prompt_name: v.string(),
  prompt_template: v.string(), 
  subsystem: v.string(),
  description: v.string(),
  workflow_step: v.string(),
  ai_model: v.string(),
  max_tokens: v.number(),
  temperature: v.number(),
  is_active: v.boolean(),
  created_at: v.number(),
})
  .index("by_name", ["prompt_name"])
  .index("by_subsystem", ["subsystem"])
```

**Testing Override Session** (new, required for testing system):
```typescript
// This will be in-memory only, NOT a database table
interface PromptTestingSession {
  sessionId: string;
  userId: string;
  promptOverrides: Map<string, string>; // prompt_name -> test_template
  variableOverrides: Map<string, any>;    // variable overrides
  activePromptName?: string;
  contextData: any; // Current workflow context
  createdAt: number;
  expiresAt: number;
}
```

### API Specifications

**Required Convex Functions for Testing Override System**:

#### Testing Session Management:
```typescript
// apps/convex/promptTesting.ts
export const createTestingSession = mutation({
  args: {
    sessionToken: v.string(),
    contextData: v.any(), // Current incident/workflow context
  },
  handler: async (ctx, args) => {
    // Create in-memory testing session
    // Extract all available variables from context
    // Return session ID and initial state
  }
});

export const getContextualVariables = query({
  args: { 
    sessionToken: v.string(),
    incidentId: v.optional(v.id("incidents")),
    workflowStep: v.optional(v.string()),
  },
  handler: async (ctx, args) => {
    // Extract all unique variables from incident workflow
    // Return with green indicators for template matches
  }
});
```

#### Prompt Resolution with Override:
```typescript
export const resolvePromptWithTesting = query({
  args: {
    sessionToken: v.string(),
    promptName: v.string(),
    testingSessionId: v.optional(v.string()),
    variableOverrides: v.optional(v.any()),
  },
  handler: async (ctx, args) => {
    // Load prompt (with testing override if session active)
    // Apply variable interpolation with overrides
    // Return resolved prompt and metadata
  }
});

export const executeTestPrompt = action({
  args: {
    sessionToken: v.string(),
    testingSessionId: v.string(),
    promptName: v.string,
    resolvedPrompt: v.string(),
    variables: v.any(),
  },
  handler: async (ctx, args) => {
    // Execute prompt against AI service
    // Return response with metadata (tokens, cost, timing)
    // Log test execution for debugging
  }
});
```

### Component Specifications

**Extended Developer Controls**: 
- `apps/web/components/incidents/DeveloperControls.tsx` - Extend existing component
- Add new prompt testing panel alongside existing "Fill Form", "Fill Narrative" buttons

**New UI Components**:
- `apps/web/components/developer/PromptTestingPanel.tsx` - Main testing interface
- `apps/web/components/developer/PromptTemplateEditor.tsx` - Template display and editing
- `apps/web/components/developer/VariablePropertyGrid.tsx` - Variable management with green indicators
- `apps/web/components/developer/PromptPreview.tsx` - Live interpolation preview
- `apps/web/components/developer/TestExecutionResults.tsx` - AI response display and analysis
- `apps/web/components/developer/PromptExporter.tsx` - Export functionality

**Integration Services**:
- `apps/web/lib/testing/prompt-testing-service.ts` - Client-side testing orchestration
- `apps/web/lib/testing/variable-extractor.ts` - Context variable extraction
- `apps/convex/lib/testing/testing-session-manager.ts` - Server-side session management
- `apps/convex/lib/testing/prompt-override-resolver.ts` - Testing-aware prompt resolution

### File Locations

**Frontend Implementation**:
- `apps/web/components/developer/` - New prompt testing components
- `apps/web/lib/testing/` - Client-side testing utilities
- `apps/web/hooks/use-prompt-testing.ts` - React hook for testing state management
- `apps/web/types/prompt-testing.ts` - TypeScript interfaces for testing

**Backend Implementation**:
- `apps/convex/promptTesting.ts` - Testing-specific Convex functions
- `apps/convex/lib/testing/` - Server-side testing utilities
- Modify existing AI service functions to support testing context parameter

### Technical Constraints [Source: docs/architecture/coding-standards.md]

**TypeScript Requirements**:
- Strict mode compliance required
- No `any` type usage except for validated variable data
- Full type safety for testing override system

**Authentication Integration** [Source: Story 6.1 patterns]:
- Use `sessionToken` + `requirePermission()` pattern for developer access
- Developer permission validation for all testing functions
- Session-based access control for testing capabilities

**Testing Override Architecture Complexity**:
- Must not break existing AI service calls when testing is inactive
- Clean abstraction layer required since pattern applies to all prompt types
- Session expiration and cleanup mechanisms required
- Fallback to normal prompt resolution when testing context unavailable

### Integration Points

**Developer Controls Extension** [Source: Existing developer toolbar screenshot]:
- Extend existing developer experience controls shown in incident workflows
- Maintain existing "Step X of Y", workflow ID display patterns
- Add prompt testing panel alongside current "Fill Form", "Fill Narrative", "Fill Q&A" buttons

**AI Service Integration** [Source: Story 6.1, 6.2]:
- Integration with questionGenerator.ts phase-specific prompts
- Support for enhancement prompts, mock answer prompts  
- Compatible with existing promptManager.getActivePrompt() calls
- Works with all AI services using template resolution

### Pattern Validation

**Repository Pattern** [Source: docs/architecture/coding-standards.md]:
- All prompt data access through repository pattern
- No direct database access from testing components  
- Centralized testing session management

**Component Integration** [Source: docs/architecture/components.md]:
- Extend existing WebApp (Next.js) → ConvexBackend integration
- Maintain existing AIToolService → ClaudeAPI call patterns
- Preserve real-time backend capabilities for live preview

## Testing

**Testing Standards** [Source: docs/testing/technical/test-strategy-and-standards.md]:

**Test File Locations** [Source: Centralized testing pattern]:
- Unit tests: `tests/web/components/developer/` - Testing interface components
- Integration tests: `tests/convex/prompt-testing/` - Testing override system
- E2E tests: `tests/e2e/developer-tools/` - Complete developer workflow testing

**Testing Frameworks**:
- **Jest + RTL**: Component testing for developer interface
- **Convex Testing**: Backend testing for testing override system
- **Playwright**: E2E testing of complete prompt testing workflow

**Key Testing Scenarios**:
- Testing override system intercepts normal prompt resolution correctly
- Variable extraction from incident context works across all phases
- Real-time interpolation updates correctly as variables change
- Export functionality produces correct machine-readable format
- Session expiration and cleanup work properly
- Developer permission validation prevents unauthorized access

**Coverage Requirements**:
- Unit tests: 85%+ coverage for testing interface components
- Integration tests: 100% coverage of testing override system
- E2E tests: Complete developer workflow from variable loading to AI execution

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-09-07 | 1.0 | Initial story creation for developer prompt testing and visualization interface | Bob (Scrum Master) |

## Dev Agent Record

*This section will be populated by Dev Agent after story completion*

### Agent Model Used
*To be filled by Dev agent*

### Debug Log References  
*To be filled by Dev agent*

### Completion Notes List
*To be filled by Dev agent*

### File List
*To be filled by Dev agent*

## QA Results

*This section will be populated by QA Agent after story completion*

### Pattern Compliance Review
*To be filled by QA agent*

### Knowledge Capture
*To be filled by QA agent*

### Velocity Data
*To be filled by QA agent*