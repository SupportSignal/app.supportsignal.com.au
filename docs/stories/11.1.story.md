# Story 11.1: Extend Unified Prompt System (Backend)

## Status
Ready

## Story
**As a** system administrator and Angela (AI prompt administrator),
**I want** extended backend schema and functions to support batch analysis prompts,
**so that** I can configure data sources for parallel AI analysis and track analysis executions with their results.

## Acceptance Criteria

1. **Schema Extension - ai_prompts Table**: Add fields to support batch analysis
   - [ ] `execution_mode` (single/batch_analysis) - determines how prompt is used
   - [ ] `prompt_type` (generation/predicate/classification/observation) - categorizes prompt purpose
   - [ ] `data_source_id` (optional FK to data_source_profiles) - links batch prompts to data sources
   - [ ] `output_format` (optional JSON schema) - defines expected output structure for analysis prompts
   - [ ] `display_order` (optional number) - controls prompt execution order in batch

2. **New Table - data_source_profiles**: System admin configures analysis targets
   - [ ] Create table with fields: `name`, `description`, `entity_type` (incident/narrative/moment), `config` (JSON), `status` (active/inactive/error), `created_by`, `last_run_at`
   - [ ] Index on `entity_type` and `status` for filtering
   - [ ] Validation: Cannot delete data source with active prompts linked

3. **New Table - analysis_executions**: Tracks batch analysis runs
   - [ ] Create table with fields: `data_source_id`, `entity_id` (incident/narrative ID), `status` (pending/running/completed/failed), `started_at`, `completed_at`, `prompt_count`, `correlation_id`
   - [ ] Index on `entity_id`, `status`, and `correlation_id`
   - [ ] Auto-populate `correlation_id` for tracing

4. **New Table - analysis_results**: Stores individual prompt results from batch runs
   - [ ] Create table with fields: `execution_id`, `prompt_id`, `output` (JSON), `tokens_used`, `processing_time_ms`, `status` (success/error), `error_message`
   - [ ] Index on `execution_id` and `prompt_id`
   - [ ] Link to both execution and prompt for queryability

5. **Backend Function - createDataSourceProfile**: System admin creates data source
   - [ ] Mutation with args: `sessionToken`, `name`, `description`, `entity_type`, `config`
   - [ ] Validate session is system admin
   - [ ] Return created data source profile ID

6. **Backend Function - listDataSourceProfiles**: All admins view data sources
   - [ ] Query with optional filters: `entity_type`, `status`
   - [ ] Return all data source profiles with prompt counts
   - [ ] Order by creation date descending

7. **Backend Function - createAnalysisPrompt**: Angela creates batch analysis prompt
   - [ ] Extends existing `createPrompt` with new fields
   - [ ] Args include: `execution_mode`, `prompt_type`, `data_source_id`, `output_format`, `display_order`
   - [ ] Validate data_source_id exists if provided
   - [ ] Return created prompt ID

8. **Backend Function - updateAnalysisPrompt**: Angela updates analysis prompt
   - [ ] Extends existing `updatePrompt` with new fields
   - [ ] Allow updating `execution_mode`, `prompt_type`, `data_source_id`, `output_format`, `display_order`
   - [ ] Return updated prompt

9. **Backend Function - listPromptsByDataSource**: Query prompts for specific data source
   - [ ] Query with args: `dataSourceId`
   - [ ] Return prompts filtered by data_source_id, ordered by display_order
   - [ ] Include prompt group information

10. **Backend Function - getPromptsByGroup**: Return prompts grouped by group_id
    - [ ] Query returning prompts organized by group
    - [ ] Filter by `execution_mode` if provided
    - [ ] Sort groups by display_order, prompts within groups by display_order

11. **Migration Script**: Migrate existing prompts to new schema
    - [ ] Add default values for new fields on existing prompts
    - [ ] Set `execution_mode='single'` for all existing prompts
    - [ ] Set `prompt_type` based on existing categories
    - [ ] Create migration rollback function

12. **Testing**: Comprehensive backend test coverage
    - [ ] Unit tests for all new mutations and queries (85%+ coverage)
    - [ ] Integration tests for data source → prompt → execution workflow
    - [ ] Test data fixtures for consistent test scenarios
    - [ ] Validation error handling tests

## Estimation & Planning

### Story Points
8

### Estimated Complexity
Medium-High

### Estimated Time
5 days (1 week)

### Risk Level
Medium

**Risk Factors**:
- Schema migrations on production data require careful testing
- Foreign key constraints must be backward-compatible with existing prompts
- Integration with existing prompt management system (Epic 6 + Story 11.0)

## Tasks / Subtasks

- [ ] **Task 1**: Extend `ai_prompts` schema (AC: 1)
  - [ ] Add `execution_mode` field (enum: single, batch_analysis) with default 'single'
  - [ ] Add `prompt_type` field (enum: generation, predicate, classification, observation)
  - [ ] Add `data_source_id` field (optional FK to data_source_profiles)
  - [ ] Add `output_format` field (optional JSON)
  - [ ] Add `display_order` field (optional number)
  - [ ] Add indexes for new fields (`by_execution_mode`, `by_data_source`)

- [ ] **Task 2**: Create `data_source_profiles` table (AC: 2)
  - [ ] Define schema with all required fields [Source: backend-patterns.md#convex-schema]
  - [ ] Add indexes for `entity_type`, `status`
  - [ ] Implement validation constraints (name uniqueness, status enum)

- [ ] **Task 3**: Create `analysis_executions` table (AC: 3)
  - [ ] Define schema with correlation_id auto-generation
  - [ ] Add indexes for `entity_id`, `status`, `correlation_id`
  - [ ] Link to data_source_profiles via FK

- [ ] **Task 4**: Create `analysis_results` table (AC: 4)
  - [ ] Define schema with FK to executions and prompts
  - [ ] Add compound index on (execution_id, prompt_id)
  - [ ] Store JSON output and performance metrics

- [ ] **Task 5**: Implement `createDataSourceProfile` mutation (AC: 5)
  - [ ] Add Convex validators for all arguments [Source: coding-standards.md#typescript-requirements]
  - [ ] Validate session is system admin using permissions module
  - [ ] Insert record with status='active'
  - [ ] Return created profile ID

- [ ] **Task 6**: Implement `listDataSourceProfiles` query (AC: 6)
  - [ ] Add optional filters for entity_type and status
  - [ ] Join with prompts to get count of linked prompts
  - [ ] Order by _creationTime descending

- [ ] **Task 7**: Extend `createPrompt` to `createAnalysisPrompt` (AC: 7)
  - [ ] Add new optional fields to existing createPrompt mutation
  - [ ] Validate data_source_id exists if provided
  - [ ] Set defaults for execution_mode and prompt_type

- [ ] **Task 8**: Extend `updatePrompt` to `updateAnalysisPrompt` (AC: 8)
  - [ ] Add new optional fields to existing updatePrompt mutation
  - [ ] Validate changes don't break existing linked executions
  - [ ] Preserve backward compatibility with Epic 6 prompt updates

- [ ] **Task 9**: Implement `listPromptsByDataSource` query (AC: 9)
  - [ ] Filter prompts by data_source_id
  - [ ] Include prompt group information (join with prompt_groups)
  - [ ] Order by display_order (nulls last)

- [ ] **Task 10**: Implement `getPromptsByGroup` query (AC: 10)
  - [ ] Group prompts by group_id
  - [ ] Optional filter by execution_mode
  - [ ] Nested sort: groups by display_order, then prompts by display_order

- [ ] **Task 11**: Create migration script (AC: 11)
  - [ ] Backfill execution_mode='single' for all existing prompts
  - [ ] Map existing categories to prompt_type enum
  - [ ] Create rollback function for safety
  - [ ] Test on development environment first

- [ ] **Task 12**: Backend testing (AC: 12)
  - [ ] Unit tests for all mutations in `tests/convex/src/prompts/` [Source: test-strategy-and-standards.md#convex-function-testing]
  - [ ] Integration tests for workflows in `tests/convex/integration/prompts/`
  - [ ] Test fixtures for data sources, prompts, executions
  - [ ] Achieve 85%+ coverage target

## Documentation Impact Assessment

**Architectural Patterns**:
- Multi-table schema extension pattern (extending existing tables + adding related tables)
- Data source abstraction pattern for flexible entity targeting
- Execution tracking pattern with correlation IDs for observability

**Documentation Updates Needed**:
- `docs/architecture/data-models.md` - Add new table schemas (data_source_profiles, analysis_executions, analysis_results)
- `docs/architecture/backend-architecture.md` - Document new Convex functions and their interaction patterns
- `docs/patterns/backend-patterns.md` - Potential new pattern: "Batch Processing with Execution Tracking"

**Examples to Create**:
- Example: Creating a data source profile for incident analysis
- Example: Linking batch analysis prompts to a data source
- Example: Querying execution history and results

## Dev Notes

### Pattern Validation

**From Previous Stories** (Story 11.0):
- Prompt group management uses drag-drop reordering with display_order
- Migration scripts must handle workflow_step → group mapping carefully
- UI integration requires real-time Convex subscriptions for prompt updates

**Established Patterns to Follow**:

**Schema Design** [Source: data-models.md#schema-structure]:
- Use snake_case for all field names
- Include `_id` (auto), `_creationTime` (auto) on all tables
- Add `processing_status` field for workflow tracking ('pending', 'processing', 'completed', 'failed')
- Include `correlation_id` for tracing related operations
- Create indexes on foreign keys and frequently queried fields

**Convex Function Architecture** [Source: backend-patterns.md#convex-function-patterns]:
- Use `mutation()` for database writes (data source CRUD, prompt updates)
- Use `query()` for reads (listing data sources, filtering prompts)
- Use `action()` if future stories need external API integration (not this story)
- Public functions: `api["prompts/dataSource"].functionName`
- Internal helpers: `internal.prompts.dataSource.helperFunction`

**TypeScript Standards** [Source: coding-standards.md#typescript-requirements]:
- Strict mode enabled, avoid `any` type
- Use Convex validators (`v.string()`, `v.id()`, `v.object()`, `v.optional()`) for all function args
- Define schema validators in `convex/schema.ts`
- No direct `process.env` access - use centralized config if needed

**Testing Requirements** [Source: test-strategy-and-standards.md#convex-function-testing]:
- Unit tests: `tests/convex/src/prompts/dataSource.test.ts`
- Integration tests: `tests/convex/integration/prompts/batchAnalysis.test.ts`
- Test fixtures: `tests/convex/fixtures/prompts.ts`, `tests/convex/fixtures/dataSources.ts`
- Coverage targets: 85%+ statements, 80%+ branches

### Testing

**Test File Locations**:
- Unit tests: `tests/convex/src/prompts/` (test individual mutations/queries)
- Integration tests: `tests/convex/integration/prompts/` (test complete workflows)
- Test fixtures: `tests/convex/fixtures/` (reusable test data)

**Testing Standards**:
- Use Jest with centralized config in `tests/convex/jest.config.js`
- Use ephemeral Convex environments for integration tests
- Test data setup in `beforeEach`, cleanup in `afterEach`
- Validate error handling for all validation scenarios

**Key Test Scenarios**:
1. **Data Source Management**: Create, list, filter by entity_type/status
2. **Prompt Extension**: Create analysis prompts with new fields, link to data sources
3. **Foreign Key Validation**: Prevent linking to non-existent data sources
4. **Migration Safety**: Verify existing prompts remain functional after migration
5. **Query Performance**: Test filtering and grouping with realistic data volumes

**Example Test Pattern** [Source: test-strategy-and-standards.md#convex-function-testing]:
```typescript
describe('Data Source Management', () => {
  beforeEach(async () => {
    await setupTestConvexEnvironment();
  });

  it('should create data source with valid config', async () => {
    const dataSource = await convex.mutation(
      api["prompts/dataSource"].createDataSource,
      {
        sessionToken: 'test-admin-token',
        name: 'Incident Analysis',
        entity_type: 'incident',
        config: { refresh_interval: 3600 },
      }
    );

    expect(dataSource.status).toBe('active');
    expect(dataSource.name).toBe('Incident Analysis');
  });
});
```

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-31 | 1.0 | Initial story draft | Bob (SM) |

## Dev Agent Record

### Agent Model Used
_To be populated by development agent_

### Debug Log References
_To be populated by development agent_

### Completion Notes
_To be populated by development agent_

### File List
_To be populated by development agent_

## QA Results

### Pattern Compliance Review
_To be populated by QA agent_

### Knowledge Capture Reference
_To be populated by QA agent after KDD process_

### Velocity Data
_To be populated by QA agent_
